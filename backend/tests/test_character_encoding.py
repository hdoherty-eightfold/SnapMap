"""
Test Character Encoding Preservation

Tests proper handling of international characters throughout the pipeline:
- Turkish: T√ºrkiye, Kayƒ±r, ƒ∞stanbul
- Spanish: Torre√≥n, Garc√≠a, Se√±or
- German: M√ºnchen, Gr√∂√üe
- French: Fran√ßais, √âl√®ve
- Complete pipeline: upload -> map -> transform -> XML
"""

import pytest
import pandas as pd
from io import BytesIO
import sys
from pathlib import Path
import xml.etree.ElementTree as ET

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.file_parser import FileParser
from app.services.xml_transformer import XMLTransformer


class TestCharacterEncoding:
    """Test character encoding preservation"""

    def setup_method(self):
        """Setup test fixtures"""
        self.parser = FileParser()
        self.transformer = XMLTransformer()

        # Test data with international characters
        self.test_data = {
            'turkish': [
                {'name': 'T√ºrkiye', 'city': 'ƒ∞stanbul', 'surname': 'Kayƒ±r'},
                {'name': '√áaƒülar', 'city': 'Ankara', 'surname': '≈ûahin'},
                {'name': '√ñmer', 'city': 'ƒ∞zmir', 'surname': 'G√ºne≈ü'}
            ],
            'spanish': [
                {'name': 'Jos√©', 'city': 'Torre√≥n', 'surname': 'Garc√≠a'},
                {'name': 'Mar√≠a', 'city': 'Le√≥n', 'surname': 'Se√±or'},
                {'name': '√Ångel', 'city': 'Arag√≥n', 'surname': 'Mu√±oz'}
            ],
            'german': [
                {'name': 'M√ºnchen', 'city': 'K√∂ln', 'surname': 'Gr√∂√üe'},
                {'name': 'J√ºrgen', 'city': 'D√ºsseldorf', 'surname': 'M√ºller'},
                {'name': 'Bj√∂rn', 'city': 'N√ºrnberg', 'surname': 'Sch√§fer'}
            ],
            'french': [
                {'name': 'Fran√ßois', 'city': 'Paris', 'surname': '√âl√®ve'},
                {'name': 'Am√©lie', 'city': 'Lyon', 'surname': 'C√¥t√©'},
                {'name': 'Ren√©', 'city': 'Orl√©ans', 'surname': 'B√©langer'}
            ]
        }

    def test_turkish_characters_in_csv(self):
        """Test Turkish character preservation in CSV parsing"""
        csv_content = """FirstName,LastName,City
T√ºrkiye,Kayƒ±r,ƒ∞stanbul
√áaƒülar,≈ûahin,Ankara
√ñmer,G√ºne≈ü,ƒ∞zmir""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        assert df.iloc[0]['FirstName'] == 'T√ºrkiye', "Should preserve Turkish √ú"
        assert df.iloc[0]['LastName'] == 'Kayƒ±r', "Should preserve Turkish ƒ±"
        assert df.iloc[0]['City'] == 'ƒ∞stanbul', "Should preserve Turkish ƒ∞"
        assert df.iloc[1]['FirstName'] == '√áaƒülar', "Should preserve Turkish √á"
        assert df.iloc[1]['LastName'] == '≈ûahin', "Should preserve Turkish ≈û"

    def test_spanish_characters_in_csv(self):
        """Test Spanish character preservation in CSV parsing"""
        csv_content = """FirstName,LastName,City
Jos√©,Garc√≠a,Torre√≥n
Mar√≠a,Se√±or,Le√≥n
√Ångel,Mu√±oz,Arag√≥n""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        assert df.iloc[0]['FirstName'] == 'Jos√©', "Should preserve Spanish √©"
        assert df.iloc[0]['LastName'] == 'Garc√≠a', "Should preserve Spanish √≠"
        assert df.iloc[0]['City'] == 'Torre√≥n', "Should preserve Spanish √≥"
        assert df.iloc[1]['LastName'] == 'Se√±or', "Should preserve Spanish √±"
        assert df.iloc[2]['FirstName'] == '√Ångel', "Should preserve Spanish √Å"

    def test_german_characters_in_csv(self):
        """Test German character preservation in CSV parsing"""
        csv_content = """FirstName,LastName,City
J√ºrgen,M√ºller,M√ºnchen
Bj√∂rn,Sch√§fer,K√∂ln
Andreas,Gr√∂√üe,D√ºsseldorf""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        assert df.iloc[0]['FirstName'] == 'J√ºrgen', "Should preserve German √º"
        assert df.iloc[0]['LastName'] == 'M√ºller', "Should preserve German √º"
        assert df.iloc[0]['City'] == 'M√ºnchen', "Should preserve German √º"
        assert df.iloc[1]['FirstName'] == 'Bj√∂rn', "Should preserve German √∂"
        assert df.iloc[2]['LastName'] == 'Gr√∂√üe', "Should preserve German √∂ and √ü"

    def test_french_characters_in_csv(self):
        """Test French character preservation in CSV parsing"""
        csv_content = """FirstName,LastName,City
Fran√ßois,√âl√®ve,Paris
Am√©lie,C√¥t√©,Lyon
Ren√©,B√©langer,Orl√©ans""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        assert df.iloc[0]['FirstName'] == 'Fran√ßois', "Should preserve French √ß"
        assert df.iloc[0]['LastName'] == '√âl√®ve', "Should preserve French √â and √®"
        assert df.iloc[1]['FirstName'] == 'Am√©lie', "Should preserve French √©"
        assert df.iloc[1]['LastName'] == 'C√¥t√©', "Should preserve French √¥ and √©"

    def test_mixed_international_characters(self):
        """Test mixed international characters in one file"""
        csv_content = """FirstName,LastName,City,Country
Jos√©,Garc√≠a,Torre√≥n,Espa√±a
J√ºrgen,M√ºller,M√ºnchen,Deutschland
Fran√ßois,√âl√®ve,Paris,France
√áaƒülar,≈ûahin,ƒ∞stanbul,T√ºrkiye""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        assert len(df) == 4, "Should parse all rows"
        assert df.iloc[0]['FirstName'] == 'Jos√©', "Spanish preserved"
        assert df.iloc[1]['FirstName'] == 'J√ºrgen', "German preserved"
        assert df.iloc[2]['FirstName'] == 'Fran√ßois', "French preserved"
        assert df.iloc[3]['FirstName'] == '√áaƒülar', "Turkish preserved"

    def test_character_encoding_in_xml_output(self):
        """Test character preservation through XML transformation"""
        # Create DataFrame with international characters
        df = pd.DataFrame({
            'FIRST_NAME': ['Jos√©', 'J√ºrgen', 'Fran√ßois', '√áaƒülar'],
            'LAST_NAME': ['Garc√≠a', 'M√ºller', '√âl√®ve', '≈ûahin'],
            'LOCATION': ['Torre√≥n', 'M√ºnchen', 'Paris', 'ƒ∞stanbul']
        })

        # Create simple mappings
        mappings = [
            {'source': 'FIRST_NAME', 'target': 'FIRST_NAME'},
            {'source': 'LAST_NAME', 'target': 'LAST_NAME'},
            {'source': 'LOCATION', 'target': 'LOCATION'}
        ]

        # Transform to XML
        xml_output = self.transformer.transform_csv_to_xml(df, mappings, "employee")

        # Parse XML to verify characters
        root = ET.fromstring(xml_output.encode('utf-8'))
        employees = root.findall('.//EF_Employee')

        assert len(employees) == 4, "Should have 4 employee records"

        # Check first employee (Spanish)
        first_name = employees[0].find('first_name')
        assert first_name is not None and first_name.text == 'Jos√©', \
            "Spanish characters preserved in XML"

        # Check second employee (German)
        last_name = employees[1].find('last_name')
        assert last_name is not None and last_name.text == 'M√ºller', \
            "German characters preserved in XML"

        # Check third employee (French)
        last_name = employees[2].find('last_name')
        assert last_name is not None and last_name.text == '√âl√®ve', \
            "French characters preserved in XML"

        # Check fourth employee (Turkish)
        location = employees[3].find('location')
        assert location is not None and location.text == 'ƒ∞stanbul', \
            "Turkish characters preserved in XML"

    def test_pipe_delimited_with_special_chars(self):
        """Test pipe-delimited files with special characters (Siemens format)"""
        csv_content = """PersonID|FirstName|LastName|Location
12345|Jos√©|Garc√≠a|Torre√≥n
67890|M√ºller|Schmidt|M√ºnchen
11111|Fran√ßois|Dubois|Orl√©ans
22222|√áaƒülar|≈ûahin|ƒ∞stanbul""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        assert metadata['detected_delimiter'] == '|', "Should detect pipe delimiter"
        assert df.iloc[0]['FirstName'] == 'Jos√©', "Spanish preserved with pipe delimiter"
        assert df.iloc[1]['FirstName'] == 'M√ºller', "German preserved with pipe delimiter"
        assert df.iloc[2]['FirstName'] == 'Fran√ßois', "French preserved with pipe delimiter"
        assert df.iloc[3]['FirstName'] == '√áaƒülar', "Turkish preserved with pipe delimiter"

    def test_encoding_detection_utf8(self):
        """Test UTF-8 encoding auto-detection"""
        csv_content = """Name,City
√úlk√º,ƒ∞zmir
Jos√©,Le√≥n""".encode('utf-8')

        format_info = self.parser.detect_file_format(csv_content, "test.csv")

        assert format_info['encoding'] in ['utf-8', 'UTF-8'], \
            "Should detect UTF-8 encoding"

    def test_special_characters_in_multi_value_fields(self):
        """Test special characters in multi-value fields with || separator"""
        csv_content = """Name|Cities
Jos√©|Torre√≥n||Le√≥n||Madrid
M√ºller|M√ºnchen||K√∂ln||D√ºsseldorf
Fran√ßois|Paris||Lyon||Orl√©ans""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        # Create mappings for multi-value field
        mappings = [
            {'source': 'Name', 'target': 'FIRST_NAME'},
            {'source': 'Cities', 'target': 'LOCATION'}
        ]

        xml_output = self.transformer.transform_csv_to_xml(df, mappings, "employee")

        # Verify multi-value fields preserved characters
        assert 'Torre√≥n' in xml_output, "Spanish √≥ preserved in multi-value field"
        assert 'M√ºnchen' in xml_output, "German √º preserved in multi-value field"
        assert 'Orl√©ans' in xml_output, "French √© preserved in multi-value field"

    def test_end_to_end_character_preservation(self):
        """Test complete pipeline: CSV -> Parse -> Transform -> XML"""
        # Create CSV with all character types
        csv_content = """PersonID|FirstName|LastName|Email|Location
1|T√ºrkiye|Kayƒ±r|turkish@example.com|ƒ∞stanbul
2|Jos√©|Garc√≠a|spanish@example.com|Torre√≥n
3|J√ºrgen|M√ºller|german@example.com|M√ºnchen
4|Fran√ßois|√âl√®ve|french@example.com|Orl√©ans""".encode('utf-8')

        # Step 1: Parse CSV
        df, metadata = self.parser.parse_file(csv_content, "test.csv")
        assert len(df) == 4, "All rows parsed"

        # Step 2: Create mappings
        mappings = [
            {'source': 'PersonID', 'target': 'EMPLOYEE_ID'},
            {'source': 'FirstName', 'target': 'FIRST_NAME'},
            {'source': 'LastName', 'target': 'LAST_NAME'},
            {'source': 'Email', 'target': 'EMAIL'},
            {'source': 'Location', 'target': 'LOCATION'}
        ]

        # Step 3: Transform to XML
        xml_output = self.transformer.transform_csv_to_xml(df, mappings, "employee")

        # Step 4: Verify all characters preserved
        # Turkish
        assert 'T√ºrkiye' in xml_output, "Turkish √ú preserved end-to-end"
        assert 'Kayƒ±r' in xml_output, "Turkish ƒ± preserved end-to-end"
        assert 'ƒ∞stanbul' in xml_output, "Turkish ƒ∞ preserved end-to-end"

        # Spanish
        assert 'Jos√©' in xml_output, "Spanish √© preserved end-to-end"
        assert 'Garc√≠a' in xml_output, "Spanish √≠ preserved end-to-end"
        assert 'Torre√≥n' in xml_output, "Spanish √≥ preserved end-to-end"

        # German
        assert 'J√ºrgen' in xml_output, "German √º preserved end-to-end"
        assert 'M√ºller' in xml_output, "German √º preserved end-to-end"
        assert 'M√ºnchen' in xml_output, "German √º preserved end-to-end"

        # French
        assert 'Fran√ßois' in xml_output, "French √ß preserved end-to-end"
        assert '√âl√®ve' in xml_output, "French √©/√® preserved end-to-end"
        assert 'Orl√©ans' in xml_output, "French √© preserved end-to-end"

        # Verify XML is valid UTF-8
        root = ET.fromstring(xml_output.encode('utf-8'))
        assert root is not None, "XML is valid UTF-8"

    def test_emoji_and_unicode_symbols(self):
        """Test handling of emojis and special unicode symbols"""
        csv_content = """Name,Department,Notes
John Smith,Engineering,Great developer ‚≠ê
Jane Doe,Sales,Top performer üèÜ
Bob Lee,HR,Helpful person üëç""".encode('utf-8')

        df, metadata = self.parser.parse_file(csv_content, "test.csv")

        # Characters should be preserved
        assert '‚≠ê' in df.iloc[0]['Notes'] or len(df.iloc[0]['Notes']) > 10
        assert 'üèÜ' in df.iloc[1]['Notes'] or len(df.iloc[1]['Notes']) > 10

    def test_windows_1252_encoding(self):
        """Test handling of Windows-1252 encoded files"""
        # Windows-1252 uses different codes for special chars
        # This is a common encoding issue
        csv_content = """FirstName,LastName
Jos√©,Garc√≠a
Mar√≠a,Mu√±oz""".encode('windows-1252')

        # Parser should handle or detect encoding properly
        try:
            df, metadata = self.parser.parse_file(csv_content, "test.csv", encoding='windows-1252')
            assert 'Jos√©' in str(df.iloc[0]['FirstName']) or 'Jos' in str(df.iloc[0]['FirstName'])
        except Exception as e:
            # If it fails, it should provide a clear error message
            assert 'encoding' in str(e).lower() or 'decode' in str(e).lower()


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
